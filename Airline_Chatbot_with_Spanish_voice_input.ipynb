{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmolBpO+OkqFrRcDxxKS8x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmalhotra18/Airline-Chatbot/blob/main/Airline_Chatbot_with_Spanish_voice_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spGuOoH5juI2"
      },
      "outputs": [],
      "source": [
        "# ‚úàÔ∏è FLIGHTAI: Multimodal Airline Chatbot (Claude + Whisper + DALL¬∑E)\n",
        "\n",
        "# =======================\n",
        "# üì¶ Imports\n",
        "# =======================\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "import base64\n",
        "import io\n",
        "import time\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from scipy.io.wavfile import write as wav_write, read as wav_read\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import anthropic\n",
        "import ffmpeg\n",
        "from IPython.display import HTML, display, Audio as IPyAudio\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "# =======================\n",
        "# üîê Environment Setup\n",
        "# =======================\n",
        "load_dotenv()\n",
        "openai = OpenAI()\n",
        "claude = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
        "\n",
        "# =======================\n",
        "# üß† System Prompt\n",
        "# =======================\n",
        "system_message = (\n",
        "    \"You are a helpful assistant for an airline called FlightAI. \"\n",
        "    \"Give short, courteous answers, no more than 1 sentence. \"\n",
        "    \"Always be accurate. If you don't know the answer, say so.\"\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# üí≥ Price / Booking Data\n",
        "# =======================\n",
        "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
        "\n",
        "def get_ticket_price(city):\n",
        "    return ticket_prices.get(city.lower(), \"Unknown\")\n",
        "\n",
        "def book_flight(destination_city, departure_date, return_date, passenger_name):\n",
        "    return {\n",
        "        \"confirmation\": f\"Booking confirmed for {passenger_name} to {destination_city}\",\n",
        "        \"flight_number\": \"AI202\",\n",
        "        \"departure_date\": departure_date,\n",
        "        \"return_date\": return_date,\n",
        "        \"gate\": \"A12\"\n",
        "    }\n",
        "\n",
        "def detect_city(text):\n",
        "    for city in ticket_prices:\n",
        "        if city in text.lower():\n",
        "            return city\n",
        "    return None\n",
        "\n",
        "# =======================\n",
        "# üñºÔ∏è Image Generation (DALL¬∑E)\n",
        "# =======================\n",
        "def artist(city):\n",
        "    try:\n",
        "        response = openai.images.generate(\n",
        "            model=\"dall-e-3\",\n",
        "            prompt=f\"A vibrant pop-art style image of vacation in {city}\",\n",
        "            size=\"1024x1024\",\n",
        "            n=1,\n",
        "            response_format=\"b64_json\",\n",
        "        )\n",
        "        image_data = base64.b64decode(response.data[0].b64_json)\n",
        "        return Image.open(io.BytesIO(image_data))\n",
        "    except Exception as e:\n",
        "        print(f\"Image error: {e}\")\n",
        "        return None\n",
        "\n",
        "# =======================\n",
        "# üó£Ô∏è Text-to-Speech (OpenAI)\n",
        "# =======================\n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"alloy\",\n",
        "        input=message\n",
        "    )\n",
        "    audio_path = \"response.mp3\"\n",
        "    with open(audio_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    return audio_path\n",
        "\n",
        "# =======================\n",
        "# üåê Translation (Claude)\n",
        "# =======================\n",
        "def translate_to_spanish_claude(text):\n",
        "    response = claude.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        system=\"Translate the following English to Spanish.\",\n",
        "        max_tokens=400,\n",
        "        messages=[{\"role\": \"user\", \"content\": text}]\n",
        "    )\n",
        "    return response.content[0].text.strip()\n",
        "\n",
        "# =======================\n",
        "# ü§ñ Claude Chat Engine\n",
        "# =======================\n",
        "def convert_history_to_prompt(history):\n",
        "    prompt = \"\"\n",
        "    for turn in history:\n",
        "        role = turn[\"role\"]\n",
        "        content = turn[\"content\"]\n",
        "        if role == \"user\":\n",
        "            prompt += f\"\\nHuman: {content}\"\n",
        "        else:\n",
        "            prompt += f\"\\nAssistant: {content}\"\n",
        "    return prompt + \"\\nAssistant:\"\n",
        "\n",
        "def chat_claude(history):\n",
        "    messages = [{\"role\": \"user\", \"content\": convert_history_to_prompt(history)}]\n",
        "    response = claude.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        system=system_message,\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7,\n",
        "        messages=messages\n",
        "    )\n",
        "    reply = response.content[0].text.strip()\n",
        "    city = detect_city(history[-1][\"content\"] if history else \"\") or detect_city(reply)\n",
        "    image = artist(city) if city else None\n",
        "    reply = f\"The price to {city.title()} is {get_ticket_price(city)}.\" if city else reply\n",
        "    spanish = translate_to_spanish_claude(reply)\n",
        "    audio_path = talker(reply)\n",
        "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    return history, image, audio_path, spanish\n",
        "\n",
        "# =======================\n",
        "# üéß Microphone Input Recorder (Colab JS)\n",
        "# =======================\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "  var data = '';\n",
        "  navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  .then(stream => {\n",
        "    const mediaRecorder = new MediaRecorder(stream);\n",
        "    mediaRecorder.start();\n",
        "    const audioChunks = [];\n",
        "    mediaRecorder.addEventListener(\"dataavailable\", event => { audioChunks.push(event.data); });\n",
        "    mediaRecorder.addEventListener(\"stop\", () => {\n",
        "      const audioBlob = new Blob(audioChunks);\n",
        "      const reader = new FileReader();\n",
        "      reader.readAsDataURL(audioBlob);\n",
        "      reader.onloadend = () => {\n",
        "        data = reader.result;\n",
        "        google.colab.kernel.invokeFunction('notebook.get_audio', [], {});\n",
        "      }\n",
        "    });\n",
        "    setTimeout(() => { mediaRecorder.stop(); }, 5000);\n",
        "  });\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "    display(HTML(AUDIO_HTML))\n",
        "    time.sleep(6)\n",
        "    data = eval_js(\"data\")\n",
        "    if not data or ',' not in data:\n",
        "        raise ValueError(\"No audio or invalid format\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    process = ffmpeg.input('pipe:0').output('pipe:1', format='wav') \\\n",
        "             .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "    output, err = process.communicate(input=binary)\n",
        "    riff_chunk_size = len(output) - 8\n",
        "    b = [0] * 4\n",
        "    q = riff_chunk_size\n",
        "    for i in range(4): q, r = divmod(q, 256); b[i] = r\n",
        "    riff = output[:4] + bytes(b) + output[8:]\n",
        "    sr, audio = wav_read(io.BytesIO(riff))\n",
        "    return audio, sr\n",
        "\n",
        "# =======================\n",
        "# üòä Voice Entry + Chat Execution\n",
        "# =======================\n",
        "def run_voice_chat(history):\n",
        "    print(\"\\nSpeak now (5 seconds)...\")\n",
        "    audio, sr = get_audio()\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    plt.plot(audio)\n",
        "    plt.title(\"Voice Input Waveform\")\n",
        "    plt.show()\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp:\n",
        "        wav_write(tmp.name, sr, audio)\n",
        "        audio_path = tmp.name\n",
        "\n",
        "    with open(audio_path, \"rb\") as f:\n",
        "        transcript = openai.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=f\n",
        "        ).text\n",
        "\n",
        "    print(\"\\nüìù Transcribed:\", transcript)\n",
        "    history.append({\"role\": \"user\", \"content\": transcript})\n",
        "    return chat_claude(history)\n",
        "\n",
        "# =======================\n",
        "# üîß Run Chatbot\n",
        "# =======================\n",
        "history = []\n",
        "\n",
        "# Run voice chatbot (feel free to run multiple times)\n",
        "history, img, audio_path, spanish = run_voice_chat(history)\n",
        "\n",
        "print(\"\\nüí¨ English Response:\", history[-1][\"content\"])\n",
        "print(\"\\nüá™üá∏ Spanish Translation:\", spanish)\n",
        "if img:\n",
        "    display(img)\n",
        "display(IPyAudio(audio_path, autoplay=True))\n"
      ]
    }
  ]
}